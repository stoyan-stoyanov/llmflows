## TL;DR

```python
from llmflows.llms import OpenAI
from llmflows.prompts import PromptTemplate

prompt_template = PromptTemplate("Generate a title for a {style} song about {topic}.")
title_prompt = prompt_template.get_prompt(style="hip-hop", topic="friendship")
print(title_prompt)

llm = OpenAI()
song_title = llm.generate(llm_prompt)
print(song_title)

```
***
## Guide
So far, we went over LLMs in LLMFlow and we saw how we can use two types of LLMs - `OpenAI`, and `OpenAIChat`.
As we saw, the most important inputs to LLMs are its prompts.For example, the `OpenAI` LLM generates it's output based on an input prompt and 
`OpenAIChat` uses a system prompt to guide it's behavior, as well as list of prompts (message history) to generate a response.

In the previous two examples we used string constants as prompts but in some cases prompts might need to change dinamically.
Imagine you are building a web app that generates song titles. The user has to provide the `style` of the song and the `topic` of the song and 
the app would return the title. In this case we can't have a static prompt since we don't know what the user will request before they send the actual request.

Prompt templates are the second main abstraction in LLMFlows. Prompt templates are string tempaltes where the user can specify variables within the text that can be 
dynamically filled in. 

!!! info
    The `PromptTemplate` class can be imported from `llmflows.prompts`

Prompt templates are strings containing variables defined with curly brackets:
```python
from llmflows.prompts import PromptTemplate

prompt_template = PromptTemplate("Generate a title for a {style} song about {topic}.")
```

Once a prompt template is defined an actual prompt can be generated by providing the required variables. Imagine the user wants
to generate a song title in a hip-hop style about friendship:
```python
title_prompt = prompt_template.get_prompt(style="hip-hop", topic="friendship")
print(llm_prompt)
```
```commandline
"Generate a title for a hip-hop song about friendship"
```

!!! question

    Q: What happens if we don't provide all the variables?

    A: The prompt template will raise an exception specifying that there are missing variables.

Now that we have the actual prompt we can use it with the LLM

```python
llm = OpenAI()
song_title, _, _ = llm.generate(title_prompt)
print(song_title)
```

```commandline
"True to the Crew"
```

***
[Previous](Chat LLMs.md){ .md-button }
[Next](Combining LLMs.md){ .md-button }